{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding\n",
    "\n",
    "Updated: 2020-07-01\n",
    "\n",
    "This notebook provides a brief example of fMRI decoding analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional setup for Google Colab\n",
    "!pip install numpy==1.17\n",
    "!pip install scipy==1.1\n",
    "!pip install bdpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colaboratory\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#data_dir = '/content/drive/My Drive/path/to/data/directory'\n",
    "\n",
    "# Setup for local run\n",
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import bdpy\n",
    "import bdpy.ml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import sklearn.metrics\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI data\n",
    "\n",
    "The fMRI data used in this notebook is colected in [Shen, Horikawa, Majima & Kamitani (2019) Deep image reconstruction from human brain activity. PLOS Comput Biol](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006633).\n",
    "\n",
    "In brief, the subject was presented natural images selected from ImageNet during fMRI scans.\n",
    "1200 images from 150 object categories (synsets) were used as the stimuli (thus, 8 images/category).\n",
    "50 images in different categories were presented in each run (with 5 one-back repetition trials).\n",
    "Thus, it took 3 runs to cover the 150 categories, and 24 runs to present all the images.\n",
    "In the original study, each image was presented for five times.\n",
    "So it took 120 runs in total.\n",
    "The entier data contains 6000 samples (1200 images x 5 presentations).\n",
    "Please see the paper for more details.\n",
    "\n",
    "In this notebook, we use the subset of the orignal data: fMRI data for stimuli from 10 categories are used.\n",
    "Thus, the example data contains 400 samples (8 images/categories x 10 categories x 5 presentations).\n",
    "\n",
    "The file `sub-04_task-ImageNetTraining_bold_preproc_native_VC_10cat.h5` containes preprocessed fMRI data for 24 runs from one subject.\n",
    "After slice timing correction, motion correction, and coregistration, the fMRI data\n",
    "\n",
    "The full dataset is available at <https://openneuro.org/datasets/ds001506/> (raw data) or <https://figshare.com/articles/Deep_Image_Reconstruction/7033577> (preprocessed data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdata = bdpy.BData(os.path.join(data_dir, 'sub-04_task-ImageNetTraining_bold_preproc_native_VC_10cat.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use fMRI responses in the lateral occipital cortex (LOC), which underlies object recongition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fMRI data (samples x voxels): (400, 3066)\n"
     ]
    }
   ],
   "source": [
    "# fMRI data in the lateral occipital cortex (LOC)\n",
    "fmri_data_loc = bdata.select('ROI_LOC')\n",
    "print('fMRI data (samples x voxels): {}'.format(fmri_data_loc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Stimulus labels\n",
    "stimulus_labels = bdata.get_label('stimulus_name')\n",
    "#stimulus_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run numbers\n",
    "runs = bdata.select('Run')\n",
    "\n",
    "# Regroup runs for cross-validation\n",
    "runs_groups = (runs + 2) // 3\n",
    "#runs_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of object categories\n",
    "\n",
    "Here we try decoding of object categories from the fMRI data.\n",
    "We use linear SVM for the classifier and evaluate prediction performance with leave-three-run-out cross-validation since the three runs cover the all 150 categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert stimulus labels (e.g., `n01639765_47681`) to cateogry labels (e.g., `n01639765`).\n",
    "The liberal before `_` in the stimulus labels is ImageNet synset ID representing the category.\n",
    "\n",
    "http://www.image-net.org/synset?wnid=n01639765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert stimulus labels to category labels\n",
    "category_labels = np.array([\n",
    "    lb.split('_')[0]\n",
    "    for lb in stimulus_labels\n",
    "])\n",
    "len(np.unique(category_labels))  # This should be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [05:33,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediciton accuracy: 0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cvindex = bdpy.ml.cvindex_groupwise(runs_groups)\n",
    "\n",
    "prediction_accuracy_cv = []\n",
    "\n",
    "for ind_train, ind_test in tqdm.tqdm(cvindex):\n",
    "    x_train = fmri_data_loc[ind_train, :]\n",
    "    y_train = category_labels[ind_train]\n",
    "    x_test = fmri_data_loc[ind_test, :]\n",
    "    y_test = category_labels[ind_test]\n",
    "    \n",
    "    # Normalization\n",
    "    norm_mean = np.mean(x_train, axis=0)\n",
    "    norm_scale = np.std(x_train, axis=0, ddof=1)\n",
    "    \n",
    "    x_train = (x_train - norm_mean) / norm_scale\n",
    "    x_test = (x_test - norm_mean) / norm_scale\n",
    "\n",
    "    # Model training\n",
    "    model = sklearn.svm.LinearSVC()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    prediction_accuracy_cv.append(acc)\n",
    "    \n",
    "prediction_accuracy = np.mean(prediction_accuracy_cv)\n",
    "print('Prediciton accuracy: {}'.format(prediction_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the classification with fMRI data in V1 (`ROI_V1`).\n",
    "\n",
    "[Optional] Compare the decoding accuracy between LOC and V1 and discuss the decoding accuracy from the two brain regions are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer comes here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another classification methods such as logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional] Typically, decoding or machine learning-based analysis of fMRI data is suffered from overfitting due to high dimensionality of the features (voxels). Think of a method to solve the overfitting on fMRI, implement it, and see whether it works or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code comes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
